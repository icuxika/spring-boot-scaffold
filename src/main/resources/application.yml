server:
  port: ${SERVER_PORT:8888}

  tomcat:
    accesslog:
      enabled: true
      file-date-format: .yyyy-MM-dd-HH-mm-ss
    basedir: log

  servlet:
    session:
      timeout: 86400s

spring:
  application:
    name: spring-boot-scaffold

  profiles:
    active: dev

  datasource:
    url: jdbc:mysql://${MYSQL_HOST:localhost}:${MYSQL_PORT:3306}/${MYSQL_DB_NAME:spring-boot-scaffold}?serverTimezone=Asia/Shanghai
    username: ${MYSQL_USERNAME:root}
    password: ${MYSQL_PASSWORD:ALLURE_love921}
  #    url: jdbc:h2:./h2/db_test

  redis:
    #    host: ${REDIS_HOST:localhost}
    #    port: ${REDIS_PORT:6379}
    password: ${REDIS_PASSWORD:ALLURE_love921}
    cluster:
      max-redirects: 3
      nodes:
        - 127.0.0.1:7001
        - 127.0.0.1:7002
        - 127.0.0.1:7003
        - 127.0.0.1:7004
        - 127.0.0.1:7005
        - 127.0.0.1:7006
    lettuce:
      pool:
        max-active: 8 # 连接池最大连接数
        max-idle: 8 # 连接池的最大空闲连接
        min-idle: 0 # 连接池的最小空闲连接
        max-wait: -1ms # 连接池最大阻塞等待时间

  session:
    store-type: redis
    redis:
      flush-mode: on_save
      namespace: spring:session

  servlet:
    multipart:
      enabled: true
      max-file-size: 512MB # 单个文件的最大上限
      max-request-size: 512MB # 单个请求的文件总大小上限

  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
    publisher-confirm-type: correlated # 配置消息到达交换器的确认回调
    publisher-returns: true # 配置消息到达队列的回调
    listener:
      simple:
        acknowledge-mode: manual
        retry:
          enabled: true
      direct:
        acknowledge-mode: manual # 设置消费端手动 ack
        retry:
          enabled: true # 是否支持重试
    template:
      retry:
        enabled: true # 开启重试机制
        initial-interval: 1000ms # 重试起始间隔时间
        max-attempts: 10 # 最大重试次数
        max-interval: 10000ms # 最大重试间隔时间
        multiplier: 2 # 间隔时间乘数。（这里配置间隔时间乘数为 2，则第一次间隔时间 1 秒，第二次重试间隔时间 2 秒，第三次 4 秒，以此类推）
      mandatory: true

  kafka:
    bootstrap-servers: 127.0.0.1:9093,127.0.0.1:9094,127.0.0.1:9095
    producer:
      retries: 3
      batch-size: 16384 # 16k
      buffer-memory: 33554432 # 32M
      acks: 1
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: default-group
      enable-auto-commit: false
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      max-poll-records: 500
    listener:
      # RECORD 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # BATCH 当每一批poll()的数据被消费者监听器处理之后提交
      # TIME 当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交
      # COUNT 当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交
      # COUNT_TIME TIME | COUNT 有一个条件满足时提交
      # MANUAL 当每一批poll()的数据被消费者监听器处理之后，手动调用Acknowledgement.acknowledge()后提交
      # MANUAL_IMMEDIATE 手动调用Acknowledgement.acknowledge()后立即提交
      ack-mode: manual_immediate

mybatis:
  configuration:
    cache-enabled: true # 启用二级缓存
    local-cache-scope: session # 一级缓存级别设置为session
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    map-underscore-to-camel-case: true
  mapper-locations: classpath:db/sqlMap/**/*.xml